{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def load_news_data(filepath):\n",
    "    news = loadmat(filepath)\n",
    "\n",
    "    # From scipy csc matrix to 2d ndarray\n",
    "    train_data = news['data'].toarray()\n",
    "    # From 2d ndarray to 1d ndarray\n",
    "    train_labels = news['labels'].flatten()\n",
    "\n",
    "    test_data = news['testdata'].toarray()\n",
    "    test_labels = news['testlabels'].flatten()\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def create_dictionary(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        list_of_words = f.readlines()\n",
    "\n",
    "    return list_of_words\n",
    "\n",
    "# This is going to be the pi_y\n",
    "def calculate_label_count_and_probability(labels):\n",
    "    label_count = defaultdict(int)\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = label_count[label] + 1\n",
    "\n",
    "    label_probability = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_probability[label] = label_count[label] / len(labels)\n",
    "\n",
    "    return label_count, label_probability\n",
    "\n",
    "def check_sum_probability(collection):\n",
    "    sum_of_probs = 0\n",
    "\n",
    "    if isinstance(collection, dict):\n",
    "        for label in label_probability:\n",
    "            sum_of_probs = sum_of_probs + label_probability[label]\n",
    "    else:\n",
    "#         print('MASUK LIST')\n",
    "        sum_of_probs = np.sum(collection)\n",
    "\n",
    "    print(sum_of_probs)\n",
    "    \n",
    "    return abs(sum_of_probs - 1.0) < 0.001\n",
    "\n",
    "# This is going to be miu_y_j\n",
    "# The idea is to calculate separately for each value of y\n",
    "# This is done by getting train_data only for a particular value of y\n",
    "# Then, sum over the word index and divide by the number of data\n",
    "def calculate_word_given_label_probability(train_data, label_count, label_probability, word_list):\n",
    "    # Return array of shape(20, 61188)\n",
    "    ret_arr = np.zeros((len(label_count), len(word_list)))\n",
    "    \n",
    "    # Iterate over label\n",
    "    for label in label_count:\n",
    "        # GOBLOK ANJING TADI train_labels == 1 WOKWOKWOK\n",
    "        idx, = np.where(train_labels == label)\n",
    "        \n",
    "        first_idx = idx[0]\n",
    "        last_idx = idx[-1]\n",
    "        \n",
    "#         print(train_data.shape)\n",
    "        \n",
    "        # Get the corresponding train_data\n",
    "        corr_train_data = train_data[first_idx:last_idx]\n",
    "#         print(corr_train_data.shape)\n",
    "        \n",
    "        # Sum over axis=0, i.e. sum word occurrence\n",
    "        word_sum = np.sum(corr_train_data, axis=0)\n",
    "#         print(word_sum.shape)\n",
    "        word_sum = np.add(word_sum, 1)\n",
    "#         print(np.max(word_sum) < label_count[label] + 2)\n",
    "        \n",
    "        # Divide by label_count + 2 (laplace_smoothing)\n",
    "#         print(label_count[label])\n",
    "#         word_prob = np.divide(word_sum, label_count[label]) \n",
    "        word_prob = np.divide(word_sum, label_count[label] + 2) \n",
    "#         print(word_prob[0:20])\n",
    "        \n",
    "        # Assign to ret_arr\n",
    "        ret_arr[label - 1] = word_prob\n",
    "        \n",
    "    return ret_arr\n",
    "\n",
    "# Check if for all j (words), miu_y_j sums up to 1\n",
    "# def check_word_probability(word_prob):\n",
    "#     sum_over_word_probs = np.sum(word_prob, axis=0)\n",
    "    \n",
    "#     print(sum_over_word_probs)\n",
    "    \n",
    "#     for elem in sum_over_word_probs:\n",
    "#         if not (abs(elem - 1.0) < 0.001):\n",
    "#             return False\n",
    "\n",
    "#     return True\n",
    "\n",
    "# This is going to be the P(X|Y)\n",
    "def predict(feature_vector, word_prob, label_probability):\n",
    "    # Arr of 20 elems\n",
    "    likelihood_arr = np.zeros(len(label_count))\n",
    "    \n",
    "    one_minus_feature_vector = np.add(np.multiply(feature_vector, -1), 1)\n",
    "    \n",
    "    one_minus_word_prob = np.add(np.multiply(word_prob, -1), 1)\n",
    "    \n",
    "    log_word_prob = np.log(word_prob)\n",
    "        \n",
    "    log_one_minus_word_prob = np.log(one_minus_word_prob)\n",
    "    \n",
    "    for label in label_probability:\n",
    "        pi_log_prob = np.log(label_probability[label])\n",
    "            \n",
    "        dot_product_one = np.dot(feature_vector, log_word_prob[label-1])\n",
    "        \n",
    "        dot_product_two = np.dot(one_minus_feature_vector, log_one_minus_word_prob[label-1])\n",
    "        \n",
    "        likelihood_arr[label - 1] = pi_log_prob + dot_product_one + dot_product_two\n",
    "        \n",
    "    return np.argmax(likelihood_arr) + 1\n",
    "\n",
    "def predict_multiple(feature_vectors, word_prob, label_probability):\n",
    "    # 2d ndarray of shape(len(feature_vectors), 20)\n",
    "#     likelihood_arr = np.zeros(len(feature_vectors), len(label_count))\n",
    "    \n",
    "    one_minus_feature_vectors = np.add(np.multiply(feature_vectors, -1), 1)\n",
    "    \n",
    "    one_minus_word_prob = np.add(np.multiply(word_prob, -1), 1)\n",
    "    \n",
    "    # Change label_probability to list\n",
    "    label_prob_list = []\n",
    "    for i in range(0, len(label_probability)):\n",
    "        label_prob_list.append(label_probability[i+1])\n",
    "        \n",
    "    pi_log_prob = np.log(label_prob_list)\n",
    "    \n",
    "    log_word_prob = np.log(word_prob)\n",
    "        \n",
    "    log_one_minus_word_prob = np.log(one_minus_word_prob)\n",
    "    \n",
    "    # Shape: 7520, 20\n",
    "    dot_product_one = np.dot(feature_vectors, log_word_prob.transpose())\n",
    "    \n",
    "    # Shape: 7520, 20\n",
    "    dot_product_two = np.dot(one_minus_feature_vectors, log_one_minus_word_prob.transpose())\n",
    "    \n",
    "    # pi_log_prob will be broadcasted\n",
    "    # Shape: 7520, 20\n",
    "    final_log_probs = dot_product_one + dot_product_two + pi_log_prob\n",
    "    \n",
    "    # Shape: 7520, 1\n",
    "    return np.add(np.argmax(final_log_probs, axis=1), 1)\n",
    "    \n",
    "def compute_error_rate_2(test_data, test_labels, word_prob, label_probability):\n",
    "    pred_result = predict_multiple(test_data, word_prob, label_probability)\n",
    "    \n",
    "    # COMPUTING ERROR RATES SO 1 IF WRONG PRED\n",
    "    pred_verdict = [1 if pred_result[i] != test_labels[i] else 0 for i in range(0, len(test_data))]\n",
    "    \n",
    "    return np.sum(pred_verdict) / len(pred_verdict)    \n",
    "\n",
    "def compute_error_rate(test_data, test_labels, word_prob, label_probability):\n",
    "    pred_result = np.zeros(len(test_data))\n",
    "    \n",
    "    for i in range(0, len(test_data)):\n",
    "        pred_label = predict(test_data[i], word_prob, label_probability)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        # COMPUTING ERROR RATES SO 1 IF WRONG PRED\n",
    "        if pred_label != test_labels[i]:\n",
    "            pred_result[i] = 1.0\n",
    "            \n",
    "    return np.sum(pred_result) / len(pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_news_data('news.mat')\n",
    "\n",
    "word_list = create_dictionary('news.vocab')\n",
    "\n",
    "label_count, label_probability = calculate_label_count_and_probability(train_labels)\n",
    "\n",
    "word_prob = calculate_word_given_label_probability(train_data, label_count, label_probability, word_list)\n",
    "\n",
    "# for elem in word_prob[19]:\n",
    "#     print(elem)\n",
    "\n",
    "# print(check_word_probability(word_prob))\n",
    "\n",
    "# predict(train_data[1000], word_prob, label_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7505, 20)\n",
      "(7505, 20)\n",
      "20\n",
      "(7505, 20)\n"
     ]
    }
   ],
   "source": [
    "predict_multiple(test_data, word_prob, label_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857130180140208"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error_rate(train_data, train_labels, word_prob, label_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3769487008660893"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error_rate_2(test_data, test_labels, word_prob, label_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3769487008660893"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute_error_rate(test_data, test_labels, word_prob, label_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(([1,2], [3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 1. ],\n",
       "       [1.5, 2. ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0] = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(np.multiply(y, -1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.zeros((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a + b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1.0, 1.0, 1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array(([1,2,3], [4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
