{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_dict = set([])\n",
    "# x = 0\n",
    "# for data_type in df['Description']:\n",
    "#     type_dict.add(data_type)\n",
    "#     if 'numeric' in data_type:\n",
    "#         x = x + 1\n",
    "        \n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('CodeBook-SELECT.csv')\n",
    "\n",
    "excluded = []\n",
    "for i in range(0, 377):\n",
    "    desc = df.iloc[i]['Description'] \n",
    "    varname = df.iloc[i]['VarName']\n",
    "    \n",
    "    if 'ISCO' in desc or 'ISCO' in varname:\n",
    "        excluded.append(varname)\n",
    "        \n",
    "    elif 'ISIC' in desc or 'ISIC' in varname:\n",
    "        excluded.append(varname)\n",
    "\n",
    "    elif 'mth' in desc or 'mth' in varname:\n",
    "        excluded.append(varname)\n",
    "        \n",
    "    elif 'coded' in desc or 'coded' in varname:\n",
    "        excluded.append(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "df = df.drop(['uni', 'row'] + excluded, axis=1)\n",
    "# df = df.drop(df[df.gender_r == 'Male'].sample(frac=.4).index)\n",
    "# df.hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL COLUMNS\n",
      "343\n",
      "NUM COL\n",
      "60\n",
      "INCL COL\n",
      "58\n",
      "age_r        35.658750\n",
      "yrsqual      14.757775\n",
      "yrsget       14.885500\n",
      "imyrs        10.325250\n",
      "leavedu      22.816550\n",
      "nfehrsnjr    19.184050\n",
      "nfehrsjr     70.076450\n",
      "nfehrs       99.925900\n",
      "dtype: float64\n",
      "earnhr             998.846943\n",
      "earnhrppp           24.171067\n",
      "earnhrbonus       1095.568602\n",
      "earnhrbonusppp      14.064605\n",
      "learnatwork          2.525914\n",
      "readytolearn         2.460732\n",
      "icthome              2.470036\n",
      "ictwork              2.662157\n",
      "dtype: float64\n",
      "influence             2.559651\n",
      "planning              2.344283\n",
      "readhome              2.578578\n",
      "readwork              2.754459\n",
      "taskdisc              2.428656\n",
      "writhome              2.327348\n",
      "writwork              2.682178\n",
      "job_performance    2909.906533\n",
      "dtype: float64\n",
      "v202    20.86910\n",
      "v231    20.91700\n",
      "v272    10.28980\n",
      "v196    21.27205\n",
      "v61      7.72375\n",
      "v129     6.01345\n",
      "v268     1.00485\n",
      "v206     1.21080\n",
      "dtype: float64\n",
      "v207     1.81030\n",
      "v136     1.65635\n",
      "v194     1.10880\n",
      "v283     2.98100\n",
      "v145     6.80005\n",
      "v41     25.93250\n",
      "v45      1.05555\n",
      "v110    51.97860\n",
      "dtype: float64\n",
      "v160    19.99195\n",
      "v52     18.21075\n",
      "v33      1.52440\n",
      "v184    27.15980\n",
      "v104    16.72335\n",
      "v22     34.81490\n",
      "v241    19.21340\n",
      "v135    43.52405\n",
      "dtype: float64\n",
      "v100    3.331427e+00\n",
      "v63     5.138832e+02\n",
      "v87     1.094969e+06\n",
      "v210    2.081282e+05\n",
      "v169    6.260642e+05\n",
      "v113    2.217330e+01\n",
      "v130    1.981950e+01\n",
      "v215    2.899745e+01\n",
      "dtype: float64\n",
      "v163    19.9779\n",
      "v81     40.0915\n",
      "dtype: float64\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print('ALL COLUMNS')\n",
    "print(len(df.columns))\n",
    "\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Find numeric ones\n",
    "num_col = []\n",
    "for col in df.columns:\n",
    "    if np.issubdtype(df[col].dtype, np.number):\n",
    "        num_col.append(col)\n",
    "\n",
    "print('NUM COL')\n",
    "print(len(num_col))\n",
    "\n",
    "# print(df[num_col[0:8]].mean())\n",
    "# print(df[num_col[8:16]].mean())\n",
    "# print(df[num_col[16:24]].mean())\n",
    "# print(df[num_col[24:32]].mean())\n",
    "# print(df[num_col[32:40]].mean())\n",
    "# print(df[num_col[40:48]].mean())\n",
    "# print(df[num_col[48:56]].mean())\n",
    "# print(df[num_col[56:64]].mean())\n",
    "# print(df[num_col[64:72]].mean())\n",
    "# print(df[num_col[72:80]].mean())\n",
    "# print(df[num_col[80:84]].mean())\n",
    "\n",
    "incl_num_cols = []\n",
    "for col in num_col:\n",
    "    if not df[col].isna().sum() > 10000:\n",
    "        m = df[col].mean()\n",
    "        if m >= 1.0:\n",
    "            if not (m > 9000.0 and m < 10000.0):\n",
    "                incl_num_cols.append(col)\n",
    "                \n",
    "                if m > 1990.0 and m < 2020.0:\n",
    "                    df[col] = df[col] - 1990.0\n",
    "\n",
    "print('INCL COL')\n",
    "print(len(incl_num_cols))\n",
    "\n",
    "print(df[incl_num_cols[0:8]].mean())\n",
    "print(df[incl_num_cols[8:16]].mean())\n",
    "print(df[incl_num_cols[16:24]].mean())\n",
    "print(df[incl_num_cols[24:32]].mean())\n",
    "print(df[incl_num_cols[32:40]].mean())\n",
    "print(df[incl_num_cols[40:48]].mean())\n",
    "print(df[incl_num_cols[48:56]].mean())\n",
    "print(df[incl_num_cols[56:64]].mean())\n",
    "print(df[incl_num_cols[64:72]].mean())\n",
    "print(df[incl_num_cols[72:80]].mean())\n",
    "print(df[incl_num_cols[80:84]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    print(len(colNames))\n",
    "    iter = 0\n",
    "    new_cols = []\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            new_cols = new_cols + dummies.columns.tolist()\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "            \n",
    "            iter = iter + 1\n",
    "            if (iter % 100 == 0):\n",
    "                print(iter)\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT COL\n",
      "285\n",
      "INCL COL\n",
      "58\n",
      "There were 343 columns before encoding categorical features\n",
      "270\n",
      "100\n",
      "200\n",
      "There are 1190 columns after encoding categorical features\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remove 999?\n",
    "\n",
    "cat_col = list(set(df.columns).difference(set(incl_num_cols)))\n",
    "# for col in cat_col:\n",
    "#     df[col] = df[col].astype('category').cat.codes\n",
    "    \n",
    "print('CAT COL')\n",
    "print(len(cat_col))\n",
    "\n",
    "incl_cat_cols = []\n",
    "for col in cat_col:\n",
    "    if len(df[col].unique()) < 11:\n",
    "        incl_cat_cols.append(col)\n",
    "#     incl_cat_cols.append(col)\n",
    "\n",
    "print('INCL COL')\n",
    "print(len(incl_num_cols))\n",
    "\n",
    "print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "df, incl_cat_cols = oneHotEncode(df, incl_cat_cols)\n",
    "print('There are {} columns after encoding categorical features'.format(df.shape[1]))\n",
    "\n",
    "# iter = 0\n",
    "# for col in cat_col:\n",
    "#     iter = iter + 1\n",
    "#     print(df[col].unique())\n",
    "    \n",
    "# print(iter)\n",
    "# print(df[incl_num_cols[8:16]].mean())\n",
    "# print(df[incl_num_cols[16:24]].mean())\n",
    "# print(df[incl_num_cols[24:32]].mean())\n",
    "# print(df[incl_num_cols[32:40]].mean())\n",
    "# print(df[incl_num_cols[40:48]].mean())\n",
    "# print(df[incl_num_cols[48:56]].mean())\n",
    "# print(df[incl_num_cols[56:64]].mean())\n",
    "# print(df[incl_num_cols[64:72]].mean())\n",
    "# print(df[incl_num_cols[72:80]].mean())\n",
    "# print(df[incl_num_cols[80:84]].mean())\n",
    "\n",
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "Int64Index([14325,  1595,  8896,  9916, 16891, 19812, 18347,  4482, 18627,\n",
      "            12325,\n",
      "            ...\n",
      "             8154,  8326, 12571, 11124, 12216, 16363, 11967,  9240,  5714,\n",
      "             3183],\n",
      "           dtype='int64', length=4998)\n",
      "15002\n",
      "1190\n",
      "20000\n",
      "1173\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "sampling_percentage = 40\n",
    "dropped_indexes = df[df['gender_r_Male'] == 1].sample(frac=float(sampling_percentage/100)).index\n",
    "print(float(sampling_percentage/100))\n",
    "print(dropped_indexes)\n",
    "with open('dropped_indexes_' + str(sampling_percentage) + '.pickle', 'wb') as outfile:\n",
    "    # dump information to that file\n",
    "    pickle.dump(dropped_indexes, outfile)\n",
    "\n",
    "# with open('dropped_indexes_' + '40_77473' + '.pickle', 'rb') as infile:\n",
    "#     # dump information to that file\n",
    "#     dropped_indexes = pickle.load(infile)\n",
    "\n",
    "train_df = df.drop(dropped_indexes)\n",
    "print(len(train_df))\n",
    "print(len(train_df.columns))\n",
    "train_df = train_df[incl_num_cols + incl_cat_cols]\n",
    "\n",
    "df = df[incl_num_cols + incl_cat_cols]\n",
    "print(len(df))\n",
    "print(len(df.columns))\n",
    "\n",
    "# labels = df['job_performance']\n",
    "# df = df.drop(['job_performance'], axis=1)\n",
    "# train_df = train_df.drop(['job_performance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': 28, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56556.14912592058"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = train_df.drop(['job_performance'], axis=1).values\n",
    "y_train = train_df['job_performance'].values\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [10, 20],\n",
    "#     'max_features': ['auto'],\n",
    "#     'min_samples_leaf': [50, 100],\n",
    "#     'min_samples_split': [100, 200],\n",
    "#     'n_estimators': [20, 50]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestRegressor(random_state = 40)\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "# clf = grid_search.best_estimator_\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf = RandomForestRegressor(max_depth = 10, random_state = 28)\n",
    "print(clf.get_params())\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_train = df.drop(['job_performance'], axis=1).values\n",
    "y_train = df['job_performance'].values\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55469.42203122032 -> \n",
    "\n",
    "# clf = RandomForestRegressor(max_depth=10, random_state = 28)\n",
    "# 56556.14912592058\n",
    "\n",
    "# clf = RandomForestRegressor(max_depth=10, n_estimators=50, min_samples_leaf=20, min_samples_split=50, random_state = 28)\n",
    "# 67991.14523202118\n",
    "\n",
    "# clf = RandomForestRegressor(max_depth=20, n_estimators=50, min_samples_leaf=20, min_samples_split=50, random_state = 28)\n",
    "# 52162.67905722521\n",
    "\n",
    "# clf = RandomForestRegressor(max_depth=20, n_estimators=100, min_samples_leaf=20, min_samples_split=50, random_state = 28)\n",
    "# 51599.90450678956\n",
    "\n",
    "# Best CV = 5 and final MSE, see the trend\n",
    "# {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 100, 'n_estimators': 50}\n",
    "# 77450.59768341765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2909.744898927854\n",
      "88718.46393858951\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred))\n",
    "print(np.var(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train < 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = np.where(y_train < 1500)\n",
    "y_pred[idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "print(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_idx = np.where(clf.coef_ > 0)\n",
    "# feat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[feat_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (50,172,255,256,257,258,260,268) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "         ..\n",
       "24495   NaN\n",
       "24496   NaN\n",
       "24497   NaN\n",
       "24498   NaN\n",
       "24499   NaN\n",
       "Name: job_performance, Length: 24500, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Split the data into training/testing sets\n",
    "# y_train = train_df['job_performance'].values\n",
    "# X_train = train_df[train_df.columns[feat_idx]].values\n",
    "\n",
    "# # poly = PolynomialFeatures(3)\n",
    "# # poly.fit_transform(X_train)\n",
    "\n",
    "# # gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "# # y_pred = gbm.predict(X_train)\n",
    "\n",
    "# # Create linear regression object\n",
    "# clf = linear_model.LinearRegression()\n",
    "# # clf = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_train = df['job_performance'].values\n",
    "# X_train = df[df.columns[feat_idx]].values\n",
    "\n",
    "# # poly = PolynomialFeatures(3)\n",
    "# # poly.fit_transform(X_train)\n",
    "\n",
    "# y_pred = clf.predict(X_train)\n",
    "\n",
    "# mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cntryid                France\n",
       "cntryid_e              France\n",
       "age_r                      54\n",
       "gender_r                 Male\n",
       "computerexperience        Yes\n",
       "                       ...   \n",
       "v224                     9996\n",
       "v71                      4390\n",
       "v105                     9996\n",
       "row                   15046.o\n",
       "uni                    gd2551\n",
       "Name: 0, Length: 380, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('hw4-testset-gd2551.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "    \n",
    "ga di limit max_depth -> dapet 15k gobs\n",
    "max_depth 10 di angka 55k -> cukup keknya takut overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
