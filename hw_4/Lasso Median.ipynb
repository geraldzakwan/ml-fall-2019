{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_excluded_features():\n",
    "    df = pd.read_csv('CodeBook-SELECT.csv')\n",
    "    excluded = []\n",
    "\n",
    "    for i in range(0, 377):\n",
    "        desc = df.iloc[i]['Description']\n",
    "        varname = df.iloc[i]['VarName']\n",
    "\n",
    "        if 'ISCO' in desc or 'ISCO' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'ISIC' in desc or 'ISIC' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'mth' in desc or 'mth' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'coded' in desc or 'coded' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "    return excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_included_numeric_columns(df):\n",
    "    # Find numeric columns\n",
    "    num_col = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            num_col.append(col)\n",
    "\n",
    "    print('NUM COL')\n",
    "    print(len(num_col))\n",
    "\n",
    "    incl_num_cols = []\n",
    "    for col in num_col:\n",
    "        noise = [9996, 9997, 9998, 9999, 996, 997, 998, 999]\n",
    "        df[col] = df[col].replace(noise, np.nan)\n",
    "                \n",
    "        if df[col].isna().sum() < 10000:\n",
    "            m = df[col].mean()\n",
    "            if m > 1990.0 and m < 2020.0:\n",
    "                df[col] = df[col] - 1990.0\n",
    "            incl_num_cols.append(col)\n",
    "#             if m >= 1.0:\n",
    "#                 if not (m > 9000.0 and m < 10000.0):\n",
    "#                     incl_num_cols.append(col)\n",
    "\n",
    "#                     if m > 1990.0 and m < 2020.0:\n",
    "#                         df[col] = df[col] - 1990.0\n",
    "                        \n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df.median().iloc[0])\n",
    "    df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].median().iloc[0])\n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].mean().iloc[0])\n",
    "    print('ASU 1')\n",
    "    print(df[incl_num_cols].isnull().values.any())\n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].mode())\n",
    "\n",
    "    print('INCL COL')\n",
    "    print(len(incl_num_cols))\n",
    "\n",
    "    return df, incl_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col_names):\n",
    "    print(len(col_names))\n",
    "\n",
    "    iter = 0\n",
    "    new_cols = []\n",
    "    for col in col_names:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            if len(df[col].unique()) < 3:\n",
    "                df[col] = df[col].astype('category')\n",
    "                df[col] = df[col].cat.codes\n",
    "                new_cols.append(col)\n",
    "            else:\n",
    "                dummies = pd.get_dummies(df[col],prefix=col)\n",
    "                new_cols = new_cols + dummies.columns.tolist()\n",
    "                df = pd.concat([df,dummies],axis=1)\n",
    "                #drop the encoded column\n",
    "                df.drop([col],axis = 1 , inplace=True)\n",
    "\n",
    "            iter = iter + 1\n",
    "            if (iter % 100 == 0):\n",
    "                print(iter)\n",
    "\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_included_cat_cols(df, incl_num_cols):\n",
    "    # TODO: Remove 999?\n",
    "\n",
    "    cat_col = list(set(df.columns).difference(set(incl_num_cols)))\n",
    "\n",
    "    print('CAT COL')\n",
    "    print(len(cat_col))\n",
    "\n",
    "    incl_cat_cols = []\n",
    "    for col in cat_col:\n",
    "        noise = ['9996', '9997', '9998', '9999', '996', '997', '998', '999']\n",
    "        df[col] = df[col].replace(noise, np.nan)\n",
    "        \n",
    "#         incl_cat_cols.append(col)\n",
    "        \n",
    "#         # INI PENTING BGT, KALO NGK JADI MINUS 900 MEANNYA WKWK\n",
    "        if 'v' in col and col != 'vet' and len(col) < 5:\n",
    "            if len(df[col].unique()) < 51:\n",
    "                incl_cat_cols.append(col)\n",
    "        else:\n",
    "            incl_cat_cols.append(col)\n",
    "        incl_cat_cols.append(col)\n",
    "    # for col in cat_col:\n",
    "    #     if len(df[col].unique()) < 11:\n",
    "    #             incl_cat_cols.append(col)\n",
    "    #     incl_cat_cols.append(col)\n",
    "    \n",
    "#     df[incl_cat_cols] = df[incl_cat_cols].fillna(df.mode().iloc[0])\n",
    "    df[incl_cat_cols] = df[incl_cat_cols].fillna(df[incl_cat_cols].mode().iloc[0])\n",
    "\n",
    "    print('INCL COL')\n",
    "    print(len(incl_num_cols))\n",
    "\n",
    "    print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "    df, incl_cat_cols = one_hot_encode(df, incl_cat_cols)\n",
    "    print('There are {} columns after encoding categorical features'.format(df.shape[1]))\n",
    "\n",
    "    return df, incl_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(df, incl_num_cols, incl_cat_cols):\n",
    "    # Drop 40% of the males to obtain balance\n",
    "#     sampling_percentage = 0\n",
    "#     sampling_percentage = 40\n",
    "#     dropped_indexes = df[df['gender_r_Male'] == 1].sample(frac=float(sampling_percentage/100), random_state = 28).index\n",
    "\n",
    "#     dropped_indexes = df[df['gender_r'] == 1].sample(frac=float(sampling_percentage/100), random_state = 28).index\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "    \n",
    "#     sm = SMOTE(random_state=42)\n",
    "    sm = SMOTE(random_state=36)\n",
    "#     sm = SMOTE(random_state=28)\n",
    "#     sm = SMOTE(random_state=0)\n",
    "    train_df, new_gender = sm.fit_resample(df[incl_num_cols + incl_cat_cols], df['gender_r'])\n",
    "    \n",
    "    train_df = pd.DataFrame(train_df, columns=df[incl_num_cols + incl_cat_cols].columns)\n",
    "\n",
    "#     with open('dropped_indexes_' + str(sampling_percentage) + '.pickle', 'wb') as outfile:\n",
    "#         # dump information to that file\n",
    "#         pickle.dump(dropped_indexes, outfile)\n",
    "\n",
    "#     train_df = df.drop(dropped_indexes)\n",
    "    print(len(train_df))\n",
    "    print(len(train_df.columns))\n",
    "#     train_df = train_df[incl_num_cols + incl_cat_cols]\n",
    "\n",
    "    df = df[incl_num_cols + incl_cat_cols]\n",
    "    print(len(df))\n",
    "    print(len(df.columns))\n",
    "    \n",
    "    print('---')\n",
    "    print(len(train_df[train_df['gender_r'] == 0]))\n",
    "    print(len(train_df[train_df['gender_r'] == 1]))\n",
    "    print('---')\n",
    "\n",
    "    return df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "def train_and_eval(df, train_df):\n",
    "    X_train = train_df.drop(['job_performance'], axis=1).values\n",
    "    y_train = train_df['job_performance'].values\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV\n",
    "    # # Create the parameter grid based on the results of random search\n",
    "    # param_grid = {\n",
    "    #     'bootstrap': [True],\n",
    "    #     'max_depth': [10, 20],\n",
    "    #     'max_features': ['auto'],\n",
    "    #     'min_samples_leaf': [50, 100],\n",
    "    #     'min_samples_split': [100, 200],\n",
    "    #     'n_estimators': [20, 50]\n",
    "    # }\n",
    "    # # Create a based model\n",
    "    # rf = RandomForestRegressor(random_state = 40)\n",
    "    # # Instantiate the grid search model\n",
    "    # grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "    # grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Create the parameter grid based on the results of random search\n",
    "#     param_grid = {\n",
    "#         'alpha': [0.1, 0.2, 0.5, 1.0]\n",
    "#     }\n",
    "#     # Create a based model\n",
    "#     rf = linear_model.Lasso(random_state = 28)\n",
    "#     # Instantiate the grid search model\n",
    "#     grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 10, n_jobs = -1, verbose = 2)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     print(grid_search.best_params_)\n",
    "#     clf = grid_search.best_estimator_\n",
    "    \n",
    "    # can be any estimator that has attribute 'feature_importances_' or 'coef_'\n",
    "#     model = RandomForestRegressor(random_state=28) \n",
    "\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     fs = SelectFromModel(model, prefit=True)\n",
    "\n",
    "#     X_train_new = fs.transform(X_train) # columns selected\n",
    "    \n",
    "#     print(len(X_train_new[0]))\n",
    "#     print(X_train_new.columns)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "#     clf = RandomForestRegressor(max_depth = 20, min_samples_leaf = 25, min_samples_split = 50, n_estimators = 100, random_state = 28)\n",
    "#     clf = linear_model.LinearRegression()\n",
    "#     clf = linear_model.Lasso(alpha=1.0, max_iter=1000)\n",
    "    clf = linear_model.Lasso(alpha=0.1, max_iter=1000)\n",
    "#     clf = linear_model.Ridge(alpha=1.0)\n",
    "    # {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 100, 'n_estimators': 50}\n",
    "#     print(clf.get_params())\n",
    "#     clf = linear_model.LinearRegression()\n",
    "#     scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    scores = cross_validate(clf, X_train, y_train, cv=10, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    print(scores)\n",
    "    \n",
    "#     clf.fit(X_train_new, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "#     X_train = fs.transform(df.drop(['job_performance'], axis=1).values)\n",
    "    X_train = df.drop(['job_performance'], axis=1).values\n",
    "    y_train = df['job_performance'].values\n",
    "\n",
    "    y_pred = clf.predict(X_train)\n",
    "\n",
    "    print('Mean: ' + str(np.mean(y_pred)))\n",
    "    print('Median: ' + str(np.median(y_pred)))\n",
    "    print('Variance: ' + str(np.var(y_pred)))\n",
    "\n",
    "    return clf, y_pred, mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_1(model_name):\n",
    "    df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "    df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)\n",
    "\n",
    "    # Impute columns simply with mode\n",
    "#     df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "    df, incl_num_cols = get_included_numeric_columns(df)\n",
    "\n",
    "    df, incl_cat_cols = get_included_cat_cols(df, incl_num_cols)\n",
    "\n",
    "    df, train_df = prepare_train(df, incl_num_cols, incl_cat_cols)\n",
    "\n",
    "    clf, df['y_pred'], mse = train_and_eval(df, train_df)\n",
    "\n",
    "    print('MSE: ' + str(mse))\n",
    "\n",
    "    with open(model_name, 'wb') as outfile:\n",
    "        pickle.dump(clf, outfile)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_1('apa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_2(model_name, train_cols):\n",
    "    df = pd.read_csv('hw4-testset-gd2551.csv')\n",
    "    df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)\n",
    "\n",
    "    # Impute columns simply with mode\n",
    "#     df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "    df, incl_num_cols = get_included_numeric_columns(df)\n",
    "\n",
    "    df, incl_cat_cols = get_included_cat_cols(df, incl_num_cols)\n",
    "\n",
    "    for missing_col in list(set(train_cols).difference(set(df.columns))):\n",
    "        df[missing_col] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    df = df[train_cols]\n",
    "    \n",
    "#     for gajelas in ['v272', 'v52', 'v135']:\n",
    "#         df[gajelas] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    X_test = df.drop(['job_performance'], axis=1).values\n",
    "    print(np.where(np.isnan(X_test)))\n",
    "    \n",
    "    for idx in set(np.where(np.isnan(X_test))[1]):\n",
    "        X_test[:, idx] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    with open(model_name, 'rb') as infile:\n",
    "        clf = pickle.load(infile)\n",
    "\n",
    "    df['job_performance'] = clf.predict(X_test)\n",
    "\n",
    "    print('Mean: ' + str(np.mean(df['job_performance'])))\n",
    "    print('Median: ' + str(np.median(df['job_performance'])))\n",
    "    print('Variance: ' + str(np.var(df['job_performance'])))\n",
    "\n",
    "    return df, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_2('test_model.pickle', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM COL\n",
      "60\n",
      "ASU 1\n",
      "False\n",
      "INCL COL\n",
      "24\n",
      "CAT COL\n",
      "319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py:4259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCL COL\n",
      "24\n",
      "There were 343 columns before encoding categorical features\n",
      "630\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'v94'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'v94'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-91dd0ead6ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_model.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('NUMS')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(set(x).difference(set(a)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print('----')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(set(a).difference(set(x)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f577eb0ce717>\u001b[0m in \u001b[0;36mmain_1\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_included_numeric_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_included_cat_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cab008c5d837>\u001b[0m in \u001b[0;36mget_included_cat_cols\u001b[0;34m(df, incl_num_cols)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There were {} columns before encoding categorical features'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are {} columns after encoding categorical features'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-eca5ef7946be>\u001b[0m in \u001b[0;36mone_hot_encode\u001b[0;34m(df, col_names)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnew_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'v94'"
     ]
    }
   ],
   "source": [
    "x = main_1('test_model.pickle')\n",
    "# print('NUMS')\n",
    "#     print(set(x).difference(set(a)))\n",
    "# print('----')\n",
    "# print(set(a).difference(set(x)))\n",
    "# print('----')\n",
    "#\n",
    "# print('CATS')\n",
    "# print(set(y).difference(set(b)))\n",
    "# print('----')\n",
    "# print(set(b).difference(set(y)))\n",
    "# print('----')\n",
    "\n",
    "%matplotlib inline\n",
    "x.hist(column='job_performance')\n",
    "x.hist(column='y_pred')\n",
    "# len(x[x['gender_r'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[x['gender_r_Male'] == 0].hist(column='job_performance')\n",
    "# x[x['gender_r_Male'] == 0].hist(column='y_pred')\n",
    "x[x['gender_r'] == 0].hist(column='job_performance')\n",
    "x[x['gender_r'] == 0].hist(column='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[x['gender_r_Male'] == 1].hist(column='job_performance')\n",
    "# x[x['gender_r_Male'] == 1].hist(column='y_pred')\n",
    "x[x['gender_r'] == 1].hist(column='job_performance')\n",
    "x[x['gender_r'] == 1].hist(column='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a_df, a_x_test = main_2('test_model.pickle', x.drop(['y_pred'], axis=1).columns)\n",
    "a_df.hist('job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(a_df.columns[[19,20,22]])\n",
    "# a_x_test[:, 22]\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 19])))\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 20])))\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_df[a_df['gender_r_Male'] == 0].hist(column='job_performance')\n",
    "a_df[a_df['gender_r'] == 0].hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_df[a_df['gender_r_Male'] == 1].hist(column='job_performance')\n",
    "a_df[a_df['gender_r'] == 1].hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: MEDIAN and SCALER\n",
    "# kalo bisa regression bgs\n",
    "# Insight: LASSO BETTER MEAN alpha 0.1 bgs dr 0.25\n",
    "\n",
    "# LINREG FIX CORET, MEAN KECIL 1700\n",
    "# RIDGE 0.5 JG SAMA 2100\n",
    "# RIDGE 1.0 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a_df[a_df['job_performance'] <= 3200]) / 24500)\n",
    "print(len(a_df[a_df['gender_r'] == 1]))\n",
    "print(len(a_df[a_df['gender_r'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[x['job_performance'] <= 3200]) / 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_indexes = x[x['gender_r'] == 1].sample(frac=float(40/100), random_state = 28).index\n",
    "y = x.drop(dropped_indexes)\n",
    "print(len(y[y['job_performance'] <= 3200]) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[x['y_pred'] <= 3200]) / 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(a_df[a_df['job_performance'] <= 1500]['gender_r_Female'])\n",
    "print(np.sum(a_df[a_df['job_performance'] <= 1500]['gender_r']))\n",
    "print(len(a_df[a_df['job_performance'] <= 1500]['gender_r']))\n",
    "# print(a_df[a_df['job_performance'] <= 1500]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x[x['job_performance'] <= 1500]['gender_r_Female'])\n",
    "# len(x[x['job_performance'] <= 1500]['gender_r'])\n",
    "dropped_indexes = x[x['gender_r'] == 1].sample(frac=float(40/100), random_state = 28).index\n",
    "y = x.drop(dropped_indexes)\n",
    "print(len(y[y['job_performance'] <= 3200]) / len(y))\n",
    "\n",
    "print(x['job_performance'].mean())\n",
    "print(x['job_performance'].median())\n",
    "print(x['job_performance'].var())\n",
    "\n",
    "print(y['job_performance'].mean())\n",
    "print(y['job_performance'].median())\n",
    "print(y['job_performance'].var())\n",
    "\n",
    "print(len(y))\n",
    "print(len(y[y['gender_r'] == 0]))\n",
    "print(len(y[y['gender_r'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_col = []\n",
    "# for col in df.columns:\n",
    "#     if np.issubdtype(df[col].dtype, np.number):\n",
    "#         num_col.append(col)\n",
    "\n",
    "# print('NUM COL')\n",
    "# print(len(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[num_col].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(df['job_performance'].mean()))\n",
    "print('Median train: ' + str(df['job_performance'].median()))\n",
    "print('Mean male: ' + str(df[df['gender_r'] == 'Male']['job_performance'].mean()))\n",
    "print('Median male: ' + str(df[df['gender_r'] == 'Male']['job_performance'].median()))\n",
    "print('Mean female: ' + str(df[df['gender_r'] == 'Female']['job_performance'].mean()))\n",
    "print('Median female: ' + str(df[df['gender_r'] == 'Female']['job_performance'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_indexes = df[df['gender_r'] == 'Male'].sample(frac=float(40/100), random_state = 28).index\n",
    "st_df = df.drop(dropped_indexes)\n",
    "print('Mean train: ' + str(st_df['job_performance'].mean()))\n",
    "print('Median train: ' + str(st_df['job_performance'].median()))\n",
    "print('Mean male: ' + str(st_df[st_df['gender_r'] == 'Male']['job_performance'].mean()))\n",
    "print('Median male: ' + str(st_df[st_df['gender_r'] == 'Male']['job_performance'].median()))\n",
    "print('Mean female: ' + str(st_df[st_df['gender_r'] == 'Female']['job_performance'].mean()))\n",
    "print('Median female: ' + str(st_df[st_df['gender_r'] == 'Female']['job_performance'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(x['y_pred'].mean()))\n",
    "print('Median train: ' + str(x['y_pred'].median()))\n",
    "print('Mean male: ' + str(x[x['gender_r'] == 1]['y_pred'].mean()))\n",
    "print('Median male: ' + str(x[x['gender_r'] == 1]['y_pred'].median()))\n",
    "print('Mean female: ' + str(x[x['gender_r'] == 0]['y_pred'].mean()))\n",
    "print('Median female: ' + str(x[x['gender_r'] == 0]['y_pred'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(a_df['job_performance'].mean()))\n",
    "print('Median train: ' + str(a_df['job_performance'].median()))\n",
    "print('Mean male: ' + str(a_df[a_df['gender_r'] == 1]['job_performance'].mean()))\n",
    "print('Median male: ' + str(a_df[a_df['gender_r'] == 1]['job_performance'].median()))\n",
    "print('Mean female: ' + str(a_df[a_df['gender_r'] == 0]['job_performance'].mean()))\n",
    "print('Median female: ' + str(a_df[a_df['gender_r'] == 0]['job_performance'].median()))\n",
    "\n",
    "# MEAN NYA RENDAH BGT KALO GA DI SAMPLING JADI 2000 BAWAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['job_performance'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['nfehrs'].max())\n",
    "# print(df[df['nfehrs'] >= 1000.0]['nfehrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['v63'].mean())\n",
    "# print(df[df['v63'] >= 1000.0]['v63'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "final_df = pd.read_csv('hw4-testset-gd2551.csv')\n",
    "final_df['job_performance'] = a_df['job_performance']\n",
    "final_df.to_csv(index=False, path_or_buf='test_submission_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv('test_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
