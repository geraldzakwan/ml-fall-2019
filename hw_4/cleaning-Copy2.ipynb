{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CodeBook-SELECT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "type_dict = set([])\n",
    "x = 0\n",
    "for data_type in df['Description']:\n",
    "    type_dict.add(data_type)\n",
    "    if 'numeric' in data_type:\n",
    "        x = x + 1\n",
    "        \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15345\n",
      "ALL COLUMNS\n",
      "378\n",
      "CAT COL\n",
      "294\n",
      "BIN COL\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "df = df.drop(['uni', 'row'], axis=1)\n",
    "# print(len(df[df['job_performance'] == np.nan]))\n",
    "\n",
    "df = df[df['job_performance'] > 2500]\n",
    "df = df[df['job_performance'] < 3500]\n",
    "print(len(df))\n",
    "\n",
    "print('ALL COLUMNS')\n",
    "print(len(df.columns))\n",
    "\n",
    "# dropped_features = []\n",
    "# for key in df:\n",
    "#     if df[key].isna().sum() > 17500:\n",
    "#         dropped_features.append(key)\n",
    "        \n",
    "# print('DROPPED FEATURES:')\n",
    "# print(len(dropped_features))\n",
    "# df = df.drop(dropped_features, axis=1)\n",
    "\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Find numeric ones\n",
    "cat_col = []\n",
    "for col in df.columns:\n",
    "#     print(df[col])\n",
    "#     if isinstance(df[col][0], str):\n",
    "#         cat_col.append(col)\n",
    "    if not np.issubdtype(df[col].dtype, np.number):\n",
    "        cat_col.append(col)\n",
    "\n",
    "print('CAT COL')\n",
    "print(len(cat_col))\n",
    "        \n",
    "bin_col = []\n",
    "for col in cat_col:\n",
    "#     x = df[col].dropna().unique() \n",
    "#     x = x[x!='999']\n",
    "    x = df[col].unique()\n",
    "    \n",
    "    if len(x) < 1000 and len(x) > 1:\n",
    "        bin_col.append(col)\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "        \n",
    "print('BIN COL')\n",
    "print(len(bin_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "# Using Pearson Correlation\n",
    "cor = df.corr()\n",
    "cor_target = cor['job_performance']\n",
    "# cor_target\n",
    "\n",
    "relevant_features = cor_target[cor_target > -0.5]\n",
    "# print(max(relevant_features))\n",
    "# print(min(relevant_features))\n",
    "\n",
    "columns = relevant_features.keys().tolist()\n",
    "print(len(columns))\n",
    "\n",
    "# columns = list(set(columns).union(set(bin_col)))\n",
    "# print(len(columns))\n",
    "\n",
    "# import sys\n",
    "# sys.exit()\n",
    "# columns\n",
    "df = df[columns]\n",
    "print(len(columns))\n",
    "# df = df.drop(['isco1l', 'isco2l', 'v224', 'v105'], axis=1)\n",
    "# print(df.columns.get_loc('job_performance'))\n",
    "# for column in columns:\n",
    "#     print(df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['job_performance']\n",
    "df = df.drop(['job_performance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45632.735822535215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train = df.values\n",
    "y_train = labels.values\n",
    "\n",
    "# gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "# y_pred = gbm.predict(X_train)\n",
    "\n",
    "# Create linear regression object\n",
    "clf = linear_model.LinearRegression()\n",
    "# clf = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
