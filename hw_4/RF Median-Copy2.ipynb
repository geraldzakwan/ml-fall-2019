{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_excluded_features():\n",
    "    df = pd.read_csv('CodeBook-SELECT.csv')\n",
    "    excluded = []\n",
    "\n",
    "    for i in range(0, 377):\n",
    "        desc = df.iloc[i]['Description']\n",
    "        varname = df.iloc[i]['VarName']\n",
    "\n",
    "        if 'ISCO' in desc or 'ISCO' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'ISIC' in desc or 'ISIC' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'mth' in desc or 'mth' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "        elif 'coded' in desc or 'coded' in varname:\n",
    "            excluded.append(varname)\n",
    "\n",
    "    return excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_included_numeric_columns(df):\n",
    "    # Find numeric columns\n",
    "    num_col = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            num_col.append(col)\n",
    "\n",
    "    print('NUM COL')\n",
    "    print(len(num_col))\n",
    "\n",
    "    incl_num_cols = []\n",
    "    for col in num_col:\n",
    "        if not df[col].isna().sum() > 10000:\n",
    "            m = df[col].mean()\n",
    "            if m > 1990.0 and m < 2020.0:\n",
    "                df[col] = df[col] - 1990.0\n",
    "            incl_num_cols.append(col)\n",
    "#             if m >= 1.0:\n",
    "#                 if not (m > 9000.0 and m < 10000.0):\n",
    "#                     incl_num_cols.append(col)\n",
    "\n",
    "#                     if m > 1990.0 and m < 2020.0:\n",
    "#                         df[col] = df[col] - 1990.0\n",
    "                        \n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df.median().iloc[0])\n",
    "    df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].median().iloc[0])\n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].mean().iloc[0])\n",
    "    print('ASU 1')\n",
    "    print(df[incl_num_cols].isnull().values.any())\n",
    "#     df[incl_num_cols] = df[incl_num_cols].fillna(df[incl_num_cols].mode())\n",
    "\n",
    "    print('INCL COL')\n",
    "    print(len(incl_num_cols))\n",
    "\n",
    "    return df, incl_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col_names):\n",
    "    print(len(col_names))\n",
    "\n",
    "    iter = 0\n",
    "    new_cols = []\n",
    "    for col in col_names:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            new_cols = new_cols + dummies.columns.tolist()\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "\n",
    "            iter = iter + 1\n",
    "            if (iter % 100 == 0):\n",
    "                print(iter)\n",
    "\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_included_cat_cols(df, incl_num_cols):\n",
    "    # TODO: Remove 999?\n",
    "\n",
    "    cat_col = list(set(df.columns).difference(set(incl_num_cols)))\n",
    "\n",
    "    print('CAT COL')\n",
    "    print(len(cat_col))\n",
    "\n",
    "    incl_cat_cols = []\n",
    "    for col in cat_col:\n",
    "#         if 'v' in col and col != 'vet' and len(col) < 5:\n",
    "#             if len(df[col].unique()) < 11:\n",
    "#                 incl_cat_cols.append(col)\n",
    "#         else:\n",
    "#             incl_cat_cols.append(col)\n",
    "        incl_cat_cols.append(col)\n",
    "    # for col in cat_col:\n",
    "    #     if len(df[col].unique()) < 11:\n",
    "    #             incl_cat_cols.append(col)\n",
    "    #     incl_cat_cols.append(col)\n",
    "    \n",
    "#     df[incl_cat_cols] = df[incl_cat_cols].fillna(df.mode().iloc[0])\n",
    "    df[incl_cat_cols] = df[incl_cat_cols].fillna(df[incl_cat_cols].mode().iloc[0])\n",
    "\n",
    "    print('INCL COL')\n",
    "    print(len(incl_num_cols))\n",
    "\n",
    "    print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "    df, incl_cat_cols = one_hot_encode(df, incl_cat_cols)\n",
    "    print('There are {} columns after encoding categorical features'.format(df.shape[1]))\n",
    "\n",
    "    return df, incl_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(df, incl_num_cols, incl_cat_cols):\n",
    "    # Drop 40% of the males to obtain balance\n",
    "#     sampling_percentage = 0\n",
    "    sampling_percentage = 30\n",
    "    dropped_indexes = df[df['gender_r_Male'] == 1].sample(frac=float(sampling_percentage/100), random_state = 28).index\n",
    "\n",
    "    with open('dropped_indexes_' + str(sampling_percentage) + '.pickle', 'wb') as outfile:\n",
    "        # dump information to that file\n",
    "        pickle.dump(dropped_indexes, outfile)\n",
    "\n",
    "    train_df = df.drop(dropped_indexes)\n",
    "    print(len(train_df))\n",
    "    print(len(train_df.columns))\n",
    "    train_df = train_df[incl_num_cols + incl_cat_cols]\n",
    "\n",
    "    df = df[incl_num_cols + incl_cat_cols]\n",
    "    print(len(df))\n",
    "    print(len(df.columns))\n",
    "\n",
    "    return df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "def train_and_eval(df, train_df):\n",
    "    X_train = train_df.drop(['job_performance'], axis=1).values\n",
    "    y_train = train_df['job_performance'].values\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV\n",
    "    # # Create the parameter grid based on the results of random search\n",
    "    # param_grid = {\n",
    "    #     'bootstrap': [True],\n",
    "    #     'max_depth': [10, 20],\n",
    "    #     'max_features': ['auto'],\n",
    "    #     'min_samples_leaf': [50, 100],\n",
    "    #     'min_samples_split': [100, 200],\n",
    "    #     'n_estimators': [20, 50]\n",
    "    # }\n",
    "    # # Create a based model\n",
    "    # rf = RandomForestRegressor(random_state = 40)\n",
    "    # # Instantiate the grid search model\n",
    "    # grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "    # grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print(grid_search.best_params_)\n",
    "    # clf = grid_search.best_estimator_\n",
    "\n",
    "    # Train the model using the training sets\n",
    "#     clf = RandomForestRegressor(max_depth = 50, min_samples_leaf = 100, n_estimators = 100, random_state = 28)\n",
    "    clf = RandomForestRegressor(max_depth = 20, min_samples_leaf = 25, min_samples_split = 50, n_estimators = 100, random_state = 28)\n",
    "#     clf = RandomForestRegressor(max_depth = 25, min_samples_leaf = 25, n_estimators = 200, random_state = 28)\n",
    "#     clf = linear_model.LinearRegression()\n",
    "#     clf = linear_model.Lasso(alpha=0.1)\n",
    "    # {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 50, 'min_samples_split': 100, 'n_estimators': 50}\n",
    "#     print(clf.get_params())\n",
    "#     clf = linear_model.LinearRegression()\n",
    "#     scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "#     scores = cross_validate(clf, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "#     print(scores)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    X_train = df.drop(['job_performance'], axis=1).values\n",
    "    y_train = df['job_performance'].values\n",
    "\n",
    "    y_pred = clf.predict(X_train)\n",
    "\n",
    "    print('Mean: ' + str(np.mean(y_pred)))\n",
    "    print('Variance: ' + str(np.var(y_pred)))\n",
    "\n",
    "    return clf, y_pred, mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_1(model_name):\n",
    "    df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "    df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)\n",
    "\n",
    "    # Impute columns simply with mode\n",
    "#     df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "    df, incl_num_cols = get_included_numeric_columns(df)\n",
    "\n",
    "    df, incl_cat_cols = get_included_cat_cols(df, incl_num_cols)\n",
    "\n",
    "    df, train_df = prepare_train(df, incl_num_cols, incl_cat_cols)\n",
    "\n",
    "    clf, df['y_pred'], mse = train_and_eval(df, train_df)\n",
    "\n",
    "    print('MSE: ' + str(mse))\n",
    "\n",
    "    with open(model_name, 'wb') as outfile:\n",
    "        pickle.dump(clf, outfile)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_1('apa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_2(model_name, train_cols):\n",
    "    df = pd.read_csv('hw4-testset-gd2551.csv')\n",
    "    df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)\n",
    "\n",
    "    # Impute columns simply with mode\n",
    "#     df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "    df, incl_num_cols = get_included_numeric_columns(df)\n",
    "\n",
    "    df, incl_cat_cols = get_included_cat_cols(df, incl_num_cols)\n",
    "\n",
    "    for missing_col in list(set(train_cols).difference(set(df.columns))):\n",
    "        df[missing_col] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    df = df[train_cols]\n",
    "    \n",
    "#     for gajelas in ['v272', 'v52', 'v135']:\n",
    "#         df[gajelas] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    X_test = df.drop(['job_performance'], axis=1).values\n",
    "    print(np.where(np.isnan(X_test)))\n",
    "    \n",
    "    for idx in set(np.where(np.isnan(X_test))[1]):\n",
    "        X_test[:, idx] = np.zeros(24500, dtype='int')\n",
    "\n",
    "    with open(model_name, 'rb') as infile:\n",
    "        clf = pickle.load(infile)\n",
    "\n",
    "    df['job_performance'] = clf.predict(X_test)\n",
    "\n",
    "    print('Mean: ' + str(np.mean(df['job_performance'])))\n",
    "    print('Variance: ' + str(np.var(df['job_performance'])))\n",
    "\n",
    "    return df, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_2('test_model.pickle', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM COL\n",
      "84\n",
      "ASU 1\n",
      "False\n",
      "INCL COL\n",
      "36\n",
      "CAT COL\n",
      "342\n",
      "INCL COL\n",
      "36\n",
      "There were 378 columns before encoding categorical features\n",
      "342\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-30ef4193cb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_model.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('NUMS')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(set(x).difference(set(a)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print('----')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(set(a).difference(set(x)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f577eb0ce717>\u001b[0m in \u001b[0;36mmain_1\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_included_numeric_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_included_cat_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_num_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5bbfcd8b6143>\u001b[0m in \u001b[0;36mget_included_cat_cols\u001b[0;34m(df, incl_num_cols)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There were {} columns before encoding categorical features'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincl_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are {} columns after encoding categorical features'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a227ac3dd2ac>\u001b[0m in \u001b[0;36mone_hot_encode\u001b[0;34m(df, col_names)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mdummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mnew_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdummies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m#drop the encoded column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             )\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m             b = make_block(\n\u001b[0;32m-> 2054\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m     )\n\u001b[0;32m-> 1721\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = main_1('test_model.pickle')\n",
    "# print('NUMS')\n",
    "#     print(set(x).difference(set(a)))\n",
    "# print('----')\n",
    "# print(set(a).difference(set(x)))\n",
    "# print('----')\n",
    "#\n",
    "# print('CATS')\n",
    "# print(set(y).difference(set(b)))\n",
    "# print('----')\n",
    "# print(set(b).difference(set(y)))\n",
    "# print('----')\n",
    "\n",
    "%matplotlib inline\n",
    "x.hist(column='job_performance')\n",
    "x.hist(column='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x['gender_r_Male'] == 0].hist(column='job_performance')\n",
    "x[x['gender_r_Male'] == 0].hist(column='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x['gender_r_Male'] == 1].hist(column='job_performance')\n",
    "x[x['gender_r_Male'] == 1].hist(column='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a_df, a_x_test = main_2('test_model.pickle', x.drop(['y_pred'], axis=1).columns)\n",
    "a_df.hist('job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(a_df.columns[[19,20,22]])\n",
    "# a_x_test[:, 22]\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 19])))\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 20])))\n",
    "# print(np.count_nonzero(~np.isnan(a_x_test[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df[a_df['gender_r_Male'] == 0].hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df[a_df['gender_r_Male'] == 1].hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: MEDIAN and SCALER\n",
    "# kalo bisa regression bgs\n",
    "# Insight: LASSO BETTER MEDIAN\n",
    "# MEDIAN MEAN NGK NGARUH\n",
    "\n",
    "# min_sample leaf 50, max_depth 20 estimators 200 dapetnya 75k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(a_df[a_df['job_performance'] <= 3200]) / 24500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[x['job_performance'] <= 2200]) / 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[x['y_pred'] <= 3200]) / 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "df = df.drop(['uni', 'row'] + get_excluded_features(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(df['job_performance'].mean()))\n",
    "print('Median train: ' + str(df['job_performance'].median()))\n",
    "print('Mean male: ' + str(df[df['gender_r'] == 'Male']['job_performance'].mean()))\n",
    "print('Median male: ' + str(df[df['gender_r'] == 'Male']['job_performance'].median()))\n",
    "print('Mean female: ' + str(df[df['gender_r'] == 'Female']['job_performance'].mean()))\n",
    "print('Median female: ' + str(df[df['gender_r'] == 'Female']['job_performance'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(x['y_pred'].mean()))\n",
    "print('Median train: ' + str(x['y_pred'].median()))\n",
    "print('Mean male: ' + str(x[x['gender_r_Male'] == 1]['y_pred'].mean()))\n",
    "print('Median male: ' + str(x[x['gender_r_Male'] == 1]['y_pred'].median()))\n",
    "print('Mean female: ' + str(x[x['gender_r_Female'] == 1]['y_pred'].mean()))\n",
    "print('Median female: ' + str(x[x['gender_r_Female'] == 1]['y_pred'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean train: ' + str(a_df['job_performance'].mean()))\n",
    "print('Median train: ' + str(a_df['job_performance'].median()))\n",
    "print('Mean male: ' + str(a_df[a_df['gender_r_Male'] == 1]['job_performance'].mean()))\n",
    "print('Median male: ' + str(a_df[a_df['gender_r_Male'] == 1]['job_performance'].median()))\n",
    "print('Mean female: ' + str(a_df[a_df['gender_r_Female'] == 1]['job_performance'].mean()))\n",
    "print('Median female: ' + str(a_df[a_df['gender_r_Female'] == 1]['job_performance'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
