{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_dict = set([])\n",
    "# x = 0\n",
    "# for data_type in df['Description']:\n",
    "#     type_dict.add(data_type)\n",
    "#     if 'numeric' in data_type:\n",
    "#         x = x + 1\n",
    "        \n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('CodeBook-SELECT.csv')\n",
    "\n",
    "excluded = []\n",
    "for i in range(0, 377):\n",
    "    desc = df.iloc[i]['Description'] \n",
    "    varname = df.iloc[i]['VarName']\n",
    "    \n",
    "    if 'ISCO' in desc or 'ISCO' in varname:\n",
    "        excluded.append(varname)\n",
    "        \n",
    "    elif 'ISIC' in desc or 'ISIC' in varname:\n",
    "        excluded.append(varname)\n",
    "\n",
    "    elif 'mth' in desc or 'mth' in varname:\n",
    "        excluded.append(varname)\n",
    "        \n",
    "    elif 'coded' in desc or 'coded' in varname:\n",
    "        excluded.append(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('hw4-trainingset-gd2551.csv')\n",
    "df = df.drop(['uni', 'row'] + excluded, axis=1)\n",
    "# df = df.drop(df[df.gender_r == 'Male'].sample(frac=.4).index)\n",
    "# df.hist(column='job_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL COLUMNS\n",
      "343\n",
      "NUM COL\n",
      "60\n",
      "INCL COL\n",
      "58\n",
      "age_r        35.658750\n",
      "yrsqual      14.757775\n",
      "yrsget       14.885500\n",
      "imyrs        10.325250\n",
      "leavedu      22.816550\n",
      "nfehrsnjr    19.184050\n",
      "nfehrsjr     70.076450\n",
      "nfehrs       99.925900\n",
      "dtype: float64\n",
      "earnhr             998.846943\n",
      "earnhrppp           24.171067\n",
      "earnhrbonus       1095.568602\n",
      "earnhrbonusppp      14.064605\n",
      "learnatwork          2.525914\n",
      "readytolearn         2.460732\n",
      "icthome              2.470036\n",
      "ictwork              2.662157\n",
      "dtype: float64\n",
      "influence             2.559651\n",
      "planning              2.344283\n",
      "readhome              2.578578\n",
      "readwork              2.754459\n",
      "taskdisc              2.428656\n",
      "writhome              2.327348\n",
      "writwork              2.682178\n",
      "job_performance    2909.906533\n",
      "dtype: float64\n",
      "v202      20.86910\n",
      "v231      20.91700\n",
      "v272    1990.00000\n",
      "v196      21.27205\n",
      "v61     1990.00000\n",
      "v129       6.01345\n",
      "v268       1.00485\n",
      "v206       1.21080\n",
      "dtype: float64\n",
      "v207     1.81030\n",
      "v136     1.65635\n",
      "v194     1.10880\n",
      "v283     2.98100\n",
      "v145     6.80005\n",
      "v41     25.93250\n",
      "v45      1.05555\n",
      "v110    51.97860\n",
      "dtype: float64\n",
      "v160    1990.00000\n",
      "v52       18.21075\n",
      "v33        1.52440\n",
      "v184      27.15980\n",
      "v104    1990.00000\n",
      "v22       34.81490\n",
      "v241    1990.00000\n",
      "v135      43.52405\n",
      "dtype: float64\n",
      "v100    3.331427e+00\n",
      "v63     5.138832e+02\n",
      "v87     1.094969e+06\n",
      "v210    2.081282e+05\n",
      "v169    6.260642e+05\n",
      "v113    2.217330e+01\n",
      "v130    1.990000e+03\n",
      "v215    2.899745e+01\n",
      "dtype: float64\n",
      "v163    1990.0000\n",
      "v81       40.0915\n",
      "dtype: float64\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print('ALL COLUMNS')\n",
    "print(len(df.columns))\n",
    "\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Find numeric ones\n",
    "num_col = []\n",
    "for col in df.columns:\n",
    "    if np.issubdtype(df[col].dtype, np.number):\n",
    "        num_col.append(col)\n",
    "\n",
    "print('NUM COL')\n",
    "print(len(num_col))\n",
    "\n",
    "# print(df[num_col[0:8]].mean())\n",
    "# print(df[num_col[8:16]].mean())\n",
    "# print(df[num_col[16:24]].mean())\n",
    "# print(df[num_col[24:32]].mean())\n",
    "# print(df[num_col[32:40]].mean())\n",
    "# print(df[num_col[40:48]].mean())\n",
    "# print(df[num_col[48:56]].mean())\n",
    "# print(df[num_col[56:64]].mean())\n",
    "# print(df[num_col[64:72]].mean())\n",
    "# print(df[num_col[72:80]].mean())\n",
    "# print(df[num_col[80:84]].mean())\n",
    "\n",
    "incl_num_cols = []\n",
    "for col in num_col:\n",
    "    if not df[col].isna().sum() > 10000:\n",
    "        m = df[col].mean()\n",
    "        if m >= 1.0:\n",
    "            if not (m > 9000.0 and m < 10000.0):\n",
    "                incl_num_cols.append(col)\n",
    "                \n",
    "                if m > 1990.0 and m < 2020.0:\n",
    "                    df[col] = df[col] = 1990.0\n",
    "\n",
    "print('INCL COL')\n",
    "print(len(incl_num_cols))\n",
    "\n",
    "print(df[incl_num_cols[0:8]].mean())\n",
    "print(df[incl_num_cols[8:16]].mean())\n",
    "print(df[incl_num_cols[16:24]].mean())\n",
    "print(df[incl_num_cols[24:32]].mean())\n",
    "print(df[incl_num_cols[32:40]].mean())\n",
    "print(df[incl_num_cols[40:48]].mean())\n",
    "print(df[incl_num_cols[48:56]].mean())\n",
    "print(df[incl_num_cols[56:64]].mean())\n",
    "print(df[incl_num_cols[64:72]].mean())\n",
    "print(df[incl_num_cols[72:80]].mean())\n",
    "print(df[incl_num_cols[80:84]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    print(len(colNames))\n",
    "    iter = 0\n",
    "    new_cols = []\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            new_cols = new_cols + dummies.columns.tolist()\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "            \n",
    "            iter = iter + 1\n",
    "            if (iter % 100 == 0):\n",
    "                print(iter)\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT COL\n",
      "285\n",
      "INCL COL\n",
      "58\n",
      "There were 343 columns before encoding categorical features\n",
      "270\n",
      "100\n",
      "200\n",
      "There are 1190 columns after encoding categorical features\n"
     ]
    }
   ],
   "source": [
    "# Remove 999?\n",
    "\n",
    "cat_col = list(set(df.columns).difference(set(incl_num_cols)))\n",
    "# for col in cat_col:\n",
    "#     df[col] = df[col].astype('category').cat.codes\n",
    "    \n",
    "print('CAT COL')\n",
    "print(len(cat_col))\n",
    "\n",
    "incl_cat_cols = []\n",
    "for col in cat_col:\n",
    "    if len(df[col].unique()) < 11:\n",
    "        incl_cat_cols.append(col)\n",
    "\n",
    "print('INCL COL')\n",
    "print(len(incl_num_cols))\n",
    "\n",
    "print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "df, incl_cat_cols = oneHotEncode(df, incl_cat_cols)\n",
    "print('There are {} columns after encoding categorical features'.format(df.shape[1]))\n",
    "\n",
    "# iter = 0\n",
    "# for col in cat_col:\n",
    "#     iter = iter + 1\n",
    "#     print(df[col].unique())\n",
    "    \n",
    "# print(iter)\n",
    "# print(df[incl_num_cols[8:16]].mean())\n",
    "# print(df[incl_num_cols[16:24]].mean())\n",
    "# print(df[incl_num_cols[24:32]].mean())\n",
    "# print(df[incl_num_cols[32:40]].mean())\n",
    "# print(df[incl_num_cols[40:48]].mean())\n",
    "# print(df[incl_num_cols[48:56]].mean())\n",
    "# print(df[incl_num_cols[56:64]].mean())\n",
    "# print(df[incl_num_cols[64:72]].mean())\n",
    "# print(df[incl_num_cols[72:80]].mean())\n",
    "# print(df[incl_num_cols[80:84]].mean())\n",
    "\n",
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15002\n",
      "1190\n",
      "20000\n",
      "1173\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# sampling_percentage = 40\n",
    "# dropped_indexes = df[df['gender_r_Male'] == 1].sample(frac=float(sampling_percentage/100)).index\n",
    "# print(float(sampling_percentage/100))\n",
    "# print(dropped_indexes)\n",
    "# with open('dropped_indexes_' + str(sampling_percentage) + '.pickle', 'wb') as outfile:\n",
    "#     # dump information to that file\n",
    "#     pickle.dump(dropped_indexes, outfile)\n",
    "\n",
    "with open('dropped_indexes_' + '40_77473' + '.pickle', 'rb') as infile:\n",
    "    # dump information to that file\n",
    "    dropped_indexes = pickle.load(infile)\n",
    "\n",
    "train_df = df.drop(dropped_indexes)\n",
    "print(len(train_df))\n",
    "print(len(train_df.columns))\n",
    "train_df = train_df[incl_num_cols + incl_cat_cols]\n",
    "\n",
    "df = df[incl_num_cols + incl_cat_cols]\n",
    "print(len(df))\n",
    "print(len(df.columns))\n",
    "\n",
    "# labels = df['job_performance']\n",
    "# df = df.drop(['job_performance'], axis=1)\n",
    "# train_df = train_df.drop(['job_performance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train = train_df.drop(['job_performance'], axis=1).values\n",
    "y_train = train_df['job_performance'].values\n",
    "\n",
    "# poly = PolynomialFeatures(3)\n",
    "# poly.fit_transform(X_train)\n",
    "\n",
    "# gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "# y_pred = gbm.predict(X_train)\n",
    "\n",
    "# Create linear regression object\n",
    "clf = linear_model.LinearRegression()\n",
    "# clf = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_train = df.drop(['job_performance'], axis=1).values\n",
    "y_train = df['job_performance'].values\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_idx = np.where(clf.coef_ > 0)\n",
    "# feat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[feat_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training/testing sets\n",
    "# y_train = train_df['job_performance'].values\n",
    "# X_train = train_df[train_df.columns[feat_idx]].values\n",
    "\n",
    "# # poly = PolynomialFeatures(3)\n",
    "# # poly.fit_transform(X_train)\n",
    "\n",
    "# # gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "# # y_pred = gbm.predict(X_train)\n",
    "\n",
    "# # Create linear regression object\n",
    "# clf = linear_model.LinearRegression()\n",
    "# # clf = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_train = df['job_performance'].values\n",
    "# X_train = df[df.columns[feat_idx]].values\n",
    "\n",
    "# # poly = PolynomialFeatures(3)\n",
    "# # poly.fit_transform(X_train)\n",
    "\n",
    "# y_pred = clf.predict(X_train)\n",
    "\n",
    "# mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "    \n",
    "0.4 Dropped Samples for Men <br>\n",
    "Lasso 0.1 <br>\n",
    "Include categorical variable which accounts for 10 category or less <br>\n",
    "Result: 78483.30285504548 -> Sabiii ini udh against all train data (include random noise) <br>\n",
    "\n",
    "Kalo abis Lasso diambil yg pentingnya trus di LinReg lagi hasilnya jadi 99105, jelek\n",
    "\n",
    "0.4 Dropped Samples for Men <br>\n",
    "LinReg <br>\n",
    "Include categorical variable which accounts for 10 category or less <br>\n",
    "Result: 77535.61922625062 -> Sabiii ini udh against all train data (include random noise) <br>\n",
    "\n",
    "1.0 Sampling for Men <br>\n",
    "LinReg <br>\n",
    "Include categorical variable which accounts for 10 category or less <br>\n",
    "Result: 75436.67962546097 -> Sabiii ini udh against all train data (include random noise) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
